{"Policy/Action_Mean": 2.5028326511383057, "Policy/Action_Std": 0.9439915418624878, "_timestamp": 1694724601.3769507, "_runtime": 200.72263264656067, "_step": 122934, "iteration": 581, "Loss/Total": 0.4511328339576721, "Loss/Policy": -0.05666860193014145, "Loss/Entropy": -0.00013610733731184155, "Loss/Value": 1.254166841506958, "Loss/Coef_Value": 0.507937570810318, "Policy/Gradient_Norm": 1.0019123554229736, "Value/Gradient_Norm": 1.293919324874878, "Policy/Log_Std": -0.05786518380045891, "LR/LearningRate_0": 0.00027406208614118467, "LR/LearningRate_1": 0.0027406208614118455, "Reward/Min": -1524.0531045065047, "Reward/Mean": -1352.4253640984837, "Reward/Max": -1089.1944444050837}