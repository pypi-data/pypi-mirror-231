<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>LoG - Laplacian of the Gaussian &#8212; gpu_tracking 1.1.3 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <link rel="canonical" href="https://amfaber.github.io/gpu_tracking_docs/python_api/LoG.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="characterize_points - Characterize provided points" href="characterize_points.html" />
    <link rel="prev" title="batch - Trackpy-like tracking" href="batch.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="log-laplacian-of-the-gaussian">
<span id="log"></span><h1>LoG - Laplacian of the Gaussian<a class="headerlink" href="#log-laplacian-of-the-gaussian" title="Permalink to this heading">¶</a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="gpu_tracking.LoG">
<span class="sig-prename descclassname"><span class="pre">gpu_tracking.</span></span><span class="sig-name descname"><span class="pre">LoG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_or_array</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_radius</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_radius</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#gpu_tracking.LoG" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs tracking with Laplacian of the Gaussian blob detection rather than local maximum,
as Trackpy does it. Laplacian of the Gaussian is a more expensive algorithm, taking longer
to run (though this can be reduced by reducing n_radii), but offers automatic detection of
the size of the found particles, allowing tracking of particles of heterogenous sizes.
It is also better able to pick up particles that are very close to eachother, though it is
still a difficult task. It is recommended to visually inspect tracking with both trackpy-like
tracking and LoG tracking to choose the best approach and parameters for the experiment.</p>
<p>The most important parameters are “min_radius”, “max_radius”, “snr” and “search_range”.
These are discribed below.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A pandas dataframe containing the results of tracking. Which columns are present
depend on the parameters used for tracking, but the “frame”, “y”, “x” and “r” always
specify where in the video the detection is found and the size of the particle
according to LoG.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pandas.DataFrame</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>The following example tracks “path/to/video.vsi”, looking for particles with radii
between 2.2 pixels and 3.5 pixels and runs linking with a cutoff of 10 pixels.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gpu_tracking</span> <span class="k">as</span> <span class="nn">gt</span>
<span class="n">gt</span><span class="o">.</span><span class="n">LoG</span><span class="p">(</span><span class="s2">&quot;path/to/video.vsi&quot;</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="n">search_range</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_or_array</strong> – The input video. Either a file-path to where the video can be found (tiff, vsi or ets format), or a numpy array with shape                (T, Y, X), T corresponding to the time dimension, and Y and X corresponding to y and x in the output dataframe</p></li>
<li><p><strong>min_radius</strong> – The minimum radius of the radius scan of laplacian of the gaussian</p></li>
<li><p><strong>max_radius</strong> – The maximum radius of the radius scan of laplacian of the gaussian. All the parameters that are set based on defaults of                the “diameter” parameter in Trackpy style tracking instead use 2x max_radius when tracking with LoG. This can have severe                consequences if the maximum radius is set very large without also adjusting parameters that are set based on this.</p></li>
<li><p><strong>n_radii</strong> – The number of radii in the radius scan. Defaults to 10. Execution time scales linearly with this setting,                as expensive convolutions need to be calculated for each radius in the radius scan.</p></li>
<li><p><strong>log_spacing</strong> – Whether to use logarithmic spacing in the radius scan. Defaults to false, using linear spacing.</p></li>
<li><p><strong>overlap_threshold</strong> – The maximum allowed overlap before overlapping detections are culled. Defaults to 0, meaning no overlap is allowed                Setting to e.g. 0.3 allows detections to overlap by 30%, while setting to 1 disables all culling. This will generally                lead to many detections of the same particle at different radii in the radius scan, and is inadvicable</p></li>
<li><p><strong>noise_size</strong> – The sigma of a gaussian smoothing that is applied to the video during preprocessing. Defaults to 1.0.                Was introduced by Crocker-Grier to counteract some digitalization noise of CCD cameras</p></li>
<li><p><strong>smoothing_size</strong> – The side-length of the uniform convolution that subtracts local background during preprocessing. Defaults to diameter.                Setting this too low and close to the actual size of the signal runs the risk of supressing the signal, as most of the “local background”                will be the signal itself. As such, it can be beneficial to set this higher than the diameter in some cases.</p></li>
<li><p><strong>minmass</strong> – The minimum integrated intensity a particle has to have to be considered a true particle, and not a spurious                detection. Defaults to 0. This setting provides the same functionality as “minmass_snr”, only the threshold                is set as an absolute number rather than being relative to the video’s noise level. “minmass_snr” should be                preferred in most cases.</p></li>
<li><p><strong>max_iterations</strong> – The maximum number of steps that the localization refinement algorithm is allowed to take. Defaults to 10.                Increasing this number is unlikely to increase localization accuracy, as it just allows each detection to                move further away from the local maximum that seeded the algorithm.</p></li>
<li><p><strong>characterize</strong> – Whether to include the columns “Rg”, “raw”, “signal” and “ecc” in the output dataframe. Defaults to True.                “Rg” is the radius of gyration of the detection. “raw” is the integrated intensity of the particle in the                unprocessed (and not background subtracted) image. “signal” is the peak (i.e. maximum pixel value) of the                signal in the preprocessed image. “ecc” is the particle’s eccentricity. These can be helpful measures for                further processing beyond gpu_tracking.</p></li>
<li><p><strong>search_range</strong> – The search range in pixel space used for linking the particles through time. Defaults to None, meaning                that linking won’t be performed. The linking algorithm is identical to Trackpy’s linking, and does                optimal (as opposed to greedy) nearest neighbor linking.</p></li>
<li><p><strong>memory</strong> – The number of frames that a particle is allowed to disappear before reappearing, for the purposes of linking.                memory = 5 means that a particle can be gone for 5 frames, reappearing in the 6th and still be linked to the                track it had built previously. If it had reappeared in the 7th, it would instead have been considered a new                particle. Defaults to 0, and has no effect if search_range is not set.</p></li>
<li><p><strong>doughnut_correction</strong> – Whether to include the columns “raw_mass”, “raw_bg_median” and “raw_mass_corrected” in the output dataframe. Like “raw”                from characterize, “raw_mass” is the integrated intensity of the particle in the raw input image. “raw_bg_median” is the                median of the background around the particle in a hollow “doughnut” of outer radius “bg_radius”, inner radius “diameter / 2                + gap_radius”. “raw_mass_corrected” is “raw_mass” - “raw_bg_median” * #pixels_in_particle. “raw_mass_corrected” is generally                the most accurate measure we have of particle intensities.</p></li>
<li><p><strong>bg_radius</strong> – The radius to use for “doughnut_correction”. Defaults to “diameter”, i.e. twice the particles radius.</p></li>
<li><p><strong>gap_radius</strong> – An optional amount of gap between the particle and background measurement for “doughnut_correction”. Defaults to 0.0.</p></li>
<li><p><strong>snr</strong> – Primary filter for what to consider a particle and what is simply suprious detections. Defaults to 0. “snr” measures the                noise level of the video by taking the standard deviation of each frame individually and taking this to be the global                noise level. The peak of the particle in the proprocessed image must then be above [noise_level] * [snr] to be considered                a particle. Videos with a very non-uniform background cause trouble for this setting, as the global noise level will be                artificially inflated, necessitating setting a lower “snr”. This setting is a useful heuristic for setting comparable                thresholds across quite different videos, but should not be interpreted as a strict filter for only getting particles above                the set snr level.</p></li>
<li><p><strong>minmass_snr</strong> – Serves the same role as “snr”, except where “snr” filters on the particle’s peak signal, “snr_minmass” filters on the particle’s                integrated intensity, potentially squashing random high “lone peaks”. Defaults to 0.</p></li>
<li><p><strong>correct_illumination</strong> – Whether to correct the illumination profile of the video before tracking. Defaults to False. This is done by smoothing the video with sigma=30 pixels                and then dividing the raw video by the very smoothed video, leveling out any local differences in background. This can be helpful                in the case of uneven illumination profiles, but also in other cases of uneven backgrounds.</p></li>
<li><p><strong>illumination_sigma</strong> – Same as “correct_illumination”, except a sigma can be provided. Defaults to 30 if correction_illumination is True, and None otherwise, meaning that                correction will not be done. If both are provided, “illumination_sigma” takes precedence.</p></li>
<li><p><strong>illumination_correction_per_frame</strong> – When doing illumination correction, this setting controls whether to do the correction on a per-frame basis, or if the                entire video should be loaded, averaged across frames, and then the resulting average frame is the only one that is smoothed                and used to do the correction. Defaults to False, meaning that the video is loaded, averaged and smoothed before starting the actual                detection algorithm.</p></li>
<li><p><strong>adaptive_background</strong> – If “snr” or “minmass_snr” are provided, this setting allows the measurement of the global background noise level to be updated adaptively.                Once a number of particles have been detected as being above the set “snr” and “minmass_snr”, the pixels of these particles are removed                from the raw image, and the global noise level is recalculated. Particles are then tested again if they are now below the thresholds of                “snr” and “minmass_snr” with the updated noise level, and included if they now pass the check. This process can be repeated iteratively,                and “adaptive_background” sets the number of times it is repeated. Defaults to None, meaning that the process is not run at all.</p></li>
<li><p><strong>shift_threshold</strong> – The threshold for stopping the localization refinement algorithm. Defaults to 0.6, and should never be below 0.5. Generally                not recommended to change.</p></li>
<li><p><strong>linker_reset_points</strong> – A list of points at which the linking should be reset. Defaults to no reset points. Useful if a single video has points at                which the recording was paused and then later resumed. Supplying these points to this option ensures that particles that are                actually temporally very far from eachother aren’t linked together.</p></li>
<li><p><strong>frames</strong> – A sequence that specifies what frames from the video to track. For example, to only load and track the first 50 frames of a video,                frames = range(50) can be supplied. Be aware that all the frames in the sequence are assumed to be next to eachother in time, i.e.                specifying frames = [0, 1, 2, 50, 100] will attempt to link the detections in frame 2 to those in frame 50, and those in frame 50 to                those in frame 100. This can be further customized with “linker_reset_points”. Defaults to tracking all supplied frames.</p></li>
<li><p><strong>tqdm</strong> – Whether to use tqdm to report progress. Defaults to True</p></li>
<li><p><strong>channel</strong> – In case a .vsi / .ets video is supplied, this channel will be used from the video. Defaults to 0</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">gpu_tracking</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../app/toc.html">Application</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="toc.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="batch.html">batch - Trackpy-like tracking</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">LoG - Laplacian of the Gaussian</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#gpu_tracking.LoG"><code class="docutils literal notranslate"><span class="pre">LoG()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="characterize_points.html">characterize_points - Characterize provided points</a></li>
<li class="toctree-l2"><a class="reference internal" href="connect.html">connect - Associate detections from two separate videos</a></li>
<li class="toctree-l2"><a class="reference internal" href="link.html">link - Nearest neighbor linking</a></li>
<li class="toctree-l2"><a class="reference internal" href="load.html">load - Load tiff or .vsi / .ets videos</a></li>
<li class="toctree-l2"><a class="reference internal" href="mean_from_file.html">mean_from_file - Mean across frames from disk</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="toc.html">Python API</a><ul>
      <li>Previous: <a href="batch.html" title="previous chapter">batch - Trackpy-like tracking</a></li>
      <li>Next: <a href="characterize_points.html" title="next chapter">characterize_points - Characterize provided points</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, Andreas Malthe Faber.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../_sources/python_api/LoG.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>