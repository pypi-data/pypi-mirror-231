Metadata-Version: 2.1
Name: rs_bytepiece
Version: 0.0.2
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Rust
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
License-File: LICENSE
Summary: bytepiece-rs Python binding
Keywords: NLP,tokenizer,bytepiece,Deep Learning
Author: Yam(长琴) <haoshaochun@gmail.com>
Author-email: Yam(长琴) <haoshaochun@gmail.com>
License: MIT
Requires-Python: >=3.7
Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM
Project-URL: homepage, https://github.com/hscspring/bytepiece-rs
Project-URL: documentation, https://github.com/hscspring/bytepiece-rs
Project-URL: repository, https://github.com/hscspring/bytepiece-rs

# bytepiece-rs

## Install

```bash
pip install rs_bytepiece
```

## Usage

```python
from rs_bytepiece import Tokenizer

tokenizer = Tokenizer()
ids = tokenizer.encode("今天天气不错")
text = tokenizer.decode(ids)
```

## Performance

The performance is a bit faster than the original implementation. I've tested the《鲁迅全集》which has 625890 chars.

|      |      |      |
| ---- | ---- | ---- |
|      |      |      |
|      |      |      |
|      |      |      |


